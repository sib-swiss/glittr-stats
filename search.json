[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Glittr stats",
    "section": "",
    "text": "In this report you can find some general statistics about Glittr.org. The plots and statistics created are amongst others used in the manuscript. Since Glittr.org is an ongoing project these statistics are updated weekly."
  },
  {
    "objectID": "index.html#set-up-the-environment",
    "href": "index.html#set-up-the-environment",
    "title": "Glittr stats",
    "section": "Set up the environment",
    "text": "Set up the environment\nThis is required if you run this notebook locally. Loading required packages.\n\nlibrary(httr2)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(ggbreak)\nlibrary(cowplot)\nlibrary(downlit)\nlibrary(xml2)\n\nTo run locally, create a file named .env and add your GitHub PAT (variable named PAT ) and google api key (named GOOGLE_API_KEY) in there, e.g.:\n\n# this is an example, store it as .env:\nexport PAT=\"ghp_aRSRESCTZII20Lklser3H\"\nexport GOOGLE_API_KEY=\"AjKSLE5SklxuRsxwPP8s0\"\n\nNow use your UNIX terminal to source this file to get the keys as objects:\n\nsource .env\n\nIn R, get environment variables as objects:\n\npat &lt;- Sys.getenv(\"PAT\")\ngoogle_api_key &lt;- Sys.getenv(\"GOOGLE_API_KEY\")\nmatomo_api_key &lt;- Sys.getenv(\"MATOMO_API_KEY\")\n\nSetting colors. These correspond to the category colours on glittr.org.\n\nglittr_cols &lt;- c(\n  \"Scripting and languages\" =             \"#3a86ff\",\n  \"Computational methods and pipelines\" = \"#fb5607\",\n  \"Omics analysis\" =                      \"#ff006e\",\n  \"Reproducibility and data management\" = \"#ffbe0b\",\n  \"Statistics and machine learning\" =     \"#8338ec\",\n  \"Others\" =                              \"#000000\")"
  },
  {
    "objectID": "index.html#parse-repository-data",
    "href": "index.html#parse-repository-data",
    "title": "Glittr stats",
    "section": "Parse repository data",
    "text": "Parse repository data\nUsing the glittr.org REST API to get repository metadata, among which the stargazers, recency, category, license and tags.\n\nCode# while loop to loop over all pages\npage_list &lt;- list()\npage &lt;- 1\nhas_more_pages &lt;- TRUE\n\nwhile (has_more_pages) {\n  # Create and send the request with pagination\n  response &lt;- request(\"https://glittr.org/api/repositories\") |&gt;\n    req_url_query(`page[size]` = 100, `page[number]` = page) |&gt;\n    req_perform() |&gt;\n    resp_body_json()\n  \n  # Append the data to the list\n  page_list &lt;- append(page_list, response$data)\n  \n  # Check if there are more pages (this logic depends on the API's response structure)\n  has_more_pages &lt;- length(response$data) &gt; 0  # Adjust this condition based on your API's pagination logic\n  page &lt;- page + 1\n}\n\n# extract relevant items as dataframe\nrepo_info_list &lt;- lapply(page_list, function(x) data.frame(\n  repo = x$name,\n  author_name = x$author$name,\n  stargazers = x$stargazers,\n  recency = x$days_since_last_push,\n  url = x$url,\n  license = ifelse(is.null(x$license), \"none\", x$license),\n  main_tag = x$tags[[1]]$name,\n  main_category = x$tags[[1]]$category,\n  website = x$website,\n  author_profile = x$author$profile,\n  author_website = x$author$website\n))\n\nrepo_info &lt;- do.call(rbind, repo_info_list)\n\n# create a column with provider (either github or gitlab)\nrepo_info$provider &lt;- ifelse(grepl(\"github\", repo_info$url), \"github\", \"gitlab\")\n\n# create a factor for categories for sorting\nrepo_info$main_category &lt;- factor(repo_info$main_category,\n                                  levels = names(glittr_cols))\n\n# category table to keep order the same in the plots\ncat_table &lt;- table(category = repo_info$main_category)\ncat_table &lt;- sort(cat_table)\n\n\nNumber of repositories: 672"
  },
  {
    "objectID": "index.html#get-contributors-info",
    "href": "index.html#get-contributors-info",
    "title": "Glittr stats",
    "section": "Get contributors info",
    "text": "Get contributors info\nUsing the GitHub REST API to get the number of contributors for each repository on glittr.org. This takes a few minutes, so if the contributors haven’t changed, it will use a cached version.\n\nCode# take long time to run, so try to use cache results if no repos have been \n# added in the meantime\n\n# check if data/n_contributors.rds exists\nif(file.exists(\"data/n_contributors.rds\")) {\n  n_contributors &lt;- readRDS(\"data/n_contributors.rds\")\n} else {\n  n_contributors &lt;- NULL\n}\n\n# get contributors info only from github repos\nrepo_info_gh &lt;- repo_info[repo_info$provider == \"github\", ]\n\n# get contributor info from github api if update is needed\nif(!identical(sort(repo_info_gh$repo), sort(names(n_contributors)))) {\n  dir.create(\"data\", showWarnings = FALSE)\n  n_contributors &lt;- sapply(repo_info_gh$repo, function(x) {\n    \n    # get repo contributors\n    resp &lt;- request(\"https://api.github.com/repos/\") |&gt;\n      req_url_path_append(x) |&gt;\n      req_url_path_append(\"contributors\") |&gt;\n      req_url_query(per_page = 1) |&gt;\n      req_headers(\n        Accept = \"application/vnd.github+json\",\n        Authorization = paste(\"Bearer\", pat),\n        `X-GitHub-Api-Version` = \"2022-11-28\",\n      ) |&gt;\n      req_perform() \n    \n    link_url &lt;- resp_link_url(resp, \"last\")\n    if(is.null(link_url)) {\n      return(1)\n    } else {\n      npages &lt;- strsplit(link_url, \"&page=\")[[1]][2] |&gt; as.numeric()\n      return(npages)\n    }\n  })\n  \n  # overwrite rds file\n  saveRDS(n_contributors, \"data/n_contributors.rds\")\n}\n\nrepo_info_gh$contributors &lt;- n_contributors[repo_info_gh$repo]"
  },
  {
    "objectID": "index.html#get-country-information",
    "href": "index.html#get-country-information",
    "title": "Glittr stats",
    "section": "Get country information",
    "text": "Get country information\nHere we get country information for all authors and organizations. It uses the free text specified at ‘location’. Since this can be anything, we use the google REST API to translate that into country.\n\nCode# check whether author info exists for caching\nif(file.exists(\"data/author_info.rds\")) {\n  author_info &lt;- readRDS(\"data/author_info.rds\")\n  author_info_authors &lt;- unique(author_info$author) |&gt; sort()\n} else {\n  author_info_authors &lt;- NULL\n}\n\ngh_authors &lt;- repo_info$author_name[repo_info$provider == \"github\"] |&gt;\n  unique() |&gt;\n  sort()\n\n# if the author info is out of date, update it\nif(!identical(gh_authors, author_info_authors)) {\n  author_info_list &lt;- list()\n  for(author in gh_authors) {\n    \n    parsed &lt;- request(\"https://api.github.com/users/\") |&gt;\n      req_url_path_append(author) |&gt;\n      req_headers(\n        Accept = \"application/vnd.github+json\",\n        Authorization = paste(\"Bearer\", pat),\n        `X-GitHub-Api-Version` = \"2022-11-28\",\n      ) |&gt;\n      req_perform() |&gt;\n      resp_body_json()\n    \n    author_info_list[[author]] &lt;- data.frame(\n      author = parsed$login,\n      type = parsed$type,\n      name = ifelse(is.null(parsed$name), NA, parsed$name),\n      location = ifelse(is.null(parsed$location), NA, parsed$location)\n    )\n  }\n  \n  author_info &lt;- do.call(rbind, author_info_list)\n  \n  author_info_loc &lt;- author_info[!is.na(author_info$location), ]\n  \n  author_loc &lt;- author_info_loc$location\n  names(author_loc) &lt;- author_info_loc$author\n  \n  ggmap::register_google(key = google_api_key)\n  loc_info &lt;- ggmap::geocode(author_loc,\n                             output = 'all')\n  \n  get_country &lt;- function(loc_results) {\n    if(\"results\" %in% names(loc_results)) {\n      for(results in loc_results$results) {\n        address_info &lt;- results$address_components |&gt; \n          lapply(unlist) |&gt; \n          do.call(rbind, args = _) |&gt;\n          as.data.frame()\n        country &lt;- address_info$long_name[address_info$types1 == \"country\"]\n        if (length(country) == 0) next\n      }\n      if (length(country) == 0) return(NA)\n      return(country)\n    } else {\n      return(NA)\n    }\n  }\n  \n  countries &lt;- sapply(loc_info, get_country)\n  names(countries) &lt;- names(author_loc)\n  \n  author_info$country &lt;- countries[author_info$author]\n  \n  saveRDS(author_info, \"data/author_info.rds\")\n}\n\nrepo_info &lt;- merge(repo_info, author_info, by.x = \"author_name\",\n                   by.y = \"author\")\nrepo_info$country[is.na(repo_info$country)] &lt;- \"undefined\"\n\n\n\nNumber of authors: 319\nNumber of countries: 26"
  },
  {
    "objectID": "index.html#parse-tag-data",
    "href": "index.html#parse-tag-data",
    "title": "Glittr stats",
    "section": "Parse tag data",
    "text": "Parse tag data\nHere, we create tag_df that contains information for each tag by using the glittr.org API.\n\nparsed &lt;- request(\"https://glittr.org/api/tags\") |&gt;\n  req_perform() |&gt;\n  resp_body_json()\n\ntag_dfs &lt;- list()\nfor(i in seq_along(parsed)) {\n  category &lt;- parsed[[i]]$category\n  name &lt;- sapply(parsed[[i]]$tags, function(x) x$name)\n  repositories &lt;- sapply(parsed[[i]]$tags, function(x) x$repositories)\n  tag_dfs[[category]] &lt;- data.frame(name, category, repositories)\n}\n\ntag_df &lt;- do.call(rbind, tag_dfs) |&gt; arrange(repositories)\n\nNumber of tags/topics: 61"
  },
  {
    "objectID": "index.html#parse-outlink-data",
    "href": "index.html#parse-outlink-data",
    "title": "Glittr stats",
    "section": "Parse outlink data",
    "text": "Parse outlink data\nHere, we use the matomo API to retrieve outlinks to repositories. In this way, we can have an idea which repositories are popular on glittr.org and how often people click on a link. It is summarized over a year (from today).\n\nCodeurl &lt;- \"https://matomo.sib.swiss/?module=API\"\n\n# Create and send the request\nresponse &lt;- request(url) |&gt;\n  req_body_form(\n    method = \"Actions.getOutlinks\",\n    idSite = 217,\n    format = \"json\",\n    date = \"today\",\n    period = \"year\",\n    expanded = 1,\n    filter_limit = -1,\n    token_auth = matomo_api_key\n  ) |&gt;\n  req_perform() |&gt;\n  resp_body_json()\n\n## Get outlinks metadata in a dataframe\noutlinks_list &lt;- list()\nfor(domain in response) {\n  label &lt;- domain$label\n  url_info &lt;- lapply(domain$subtable, function(x) {\n    data.frame(\n      url = ifelse(is.null(x$url),NA , x$url),\n      nb_visits = ifelse(is.null(x$nb_visits),NA , x$nb_visits),\n      domain = label\n    )\n  })\n  outlinks_list[[domain$label]] &lt;- do.call(rbind, url_info)\n}\n\noutlinks_df &lt;- do.call(rbind, outlinks_list)\nrow.names(outlinks_df) &lt;- NULL\n\n# function to clean urls for matching\nclean_url &lt;- function(url) {\n  trimws(url) |&gt; gsub(\"/$\", \"\", x = _) |&gt; tolower()\n}\n\n# function to match outlink data with repo and website url per entry\nmatch_url &lt;- function(outlinks_df, repo_info, column = \"repo_url\") {\n  url_clean &lt;- clean_url(outlinks_df$url)\n  column_clean &lt;- clean_url(repo_info[[column]])\n  outlinks_df[[paste0(\"is_\", column)]] &lt;- url_clean %in% column_clean\n  outlinks_df[[paste0(\"ass_repo_\", column)]] &lt;- repo_info$repo[match(url_clean,\n                                                                    column_clean)]\n  return(outlinks_df)\n}\n\n# apply the match url function on urls associated with repo entry\nfor(column in c(\"url\", \"website\", \"author_profile\", \"author_website\")) {\n  outlinks_df &lt;- match_url(outlinks_df, repo_info, column = column)\n}\n\n# filter for only repo url and website (ignore author info)\n# check whether associations match\noutlinks_df$associated_entry &lt;- outlinks_df |&gt;\n  select(ass_repo_url, ass_repo_website) |&gt;\n  apply(1, function(x) {\n    x &lt;- x[!is.na(x)] |&gt; unique()\n    \n    if(length(x) == 1) return(x[1]) \n    if(length(x == 0) == 0) return(NA)\n    if(length(x == 2)) return(\"do not correspond\")\n  })\n\n# create a list of outlink visits by entry\nvisits_by_entry &lt;- outlinks_df |&gt;\n  select(url, nb_visits, associated_entry) |&gt;\n  filter(!is.na(associated_entry)) |&gt;\n  group_by(associated_entry) |&gt;\n  summarise(total_visits = sum(nb_visits)) \n\nvisits_by_entry &lt;- merge(visits_by_entry, repo_info,\n                         by.x = \"associated_entry\",\n                         by.y = \"repo\") |&gt;\n  arrange(desc(total_visits))\n\nvisits_by_namespace &lt;- visits_by_entry |&gt;\n  select(total_visits, author_name) |&gt;\n  group_by(author_name) |&gt;\n  summarise(total_visits = sum(total_visits)) |&gt;\n  arrange(desc(total_visits))\n\n# visits by tag\nvisits_by_main_tag &lt;- visits_by_entry |&gt;\n  select(total_visits, main_tag) |&gt;\n  group_by(main_tag) |&gt;\n  summarise(total_visits = sum(total_visits))\n\n# add main category information for plotting\nvisits_by_main_tag &lt;- merge(visits_by_main_tag, tag_df,\n                            by.x = \"main_tag\",\n                            by.y = \"name\") |&gt;\n  mutate(visits_per_repo = total_visits/repositories) |&gt;\n  arrange(desc(visits_per_repo))\n\n\n\nThe number of outlink visits in the last year: 3162\nNumber of repositories found using Glittr.org: 283\nMost popular repo was TheAlgorithms/Python with 328 outlinks.\nMost popular namespace was TheAlgorithms with 328 outlinks."
  },
  {
    "objectID": "index.html#number-of-repositories-by-category",
    "href": "index.html#number-of-repositories-by-category",
    "title": "Glittr stats",
    "section": "Number of repositories by category",
    "text": "Number of repositories by category\nThis is figure 2A in the manuscript.\n\ncat_count_plot &lt;- table(category = repo_info$main_category) |&gt;\n  as.data.frame() |&gt;\n  ggplot(aes(x = reorder(category, Freq), y = Freq, fill = category)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = glittr_cols) +\n  coord_flip() +\n  theme_classic() +\n  ggtitle(\"Categories\") +\n  theme(legend.position = \"none\",\n        axis.title.y = element_blank()) +\n  ylab(\"Number of repositories\")\n\nprint(cat_count_plot)\n\n\n\n\n\n\nFigure 1: Number of repositories per category\n\n\n\n\nAnd a table with the actual numbers\n\ncategory_count &lt;- table(category = repo_info$main_category) |&gt; as.data.frame()\nknitr::kable(category_count)\n\n\nTable 1: Number of repositories per category\n\n\n\n\ncategory\nFreq\n\n\n\nScripting and languages\n311\n\n\nComputational methods and pipelines\n48\n\n\nOmics analysis\n154\n\n\nReproducibility and data management\n45\n\n\nStatistics and machine learning\n83\n\n\nOthers\n29"
  },
  {
    "objectID": "index.html#number-of-contributors-per-repository-separated-by-category",
    "href": "index.html#number-of-contributors-per-repository-separated-by-category",
    "title": "Glittr stats",
    "section": "Number of contributors per repository separated by category",
    "text": "Number of contributors per repository separated by category\nThis is figure 2B in the manuscript.\n\nrepo_info_gh$main_category &lt;- factor(repo_info_gh$main_category,\n                                     levels = names(cat_table))\n\ncontributors_plot &lt;- repo_info_gh |&gt;\n  ggplot(aes(x = main_category, y = contributors, fill = main_category)) +\n  geom_violin(scale = \"width\") +\n  geom_boxplot(width = 0.1, col = \"darkgrey\") +\n  coord_flip() +\n  ggtitle(\"Contributors\") +\n  ylab(\"Number of contributors\") +\n  scale_y_sqrt() +\n  scale_fill_manual(values = glittr_cols) +\n  theme_bw() +\n  theme(legend.position = \"none\",\n        axis.title.y = element_blank(),\n        plot.margin = margin(t = 5, r = 10, b = 5, l = 10))\n\nprint(contributors_plot)\n\n\n\n\n\n\nFigure 2: Number of contributors per repository separated by category\n\n\n\n\nAnd some statistics of contributors.\n\nnna_contr &lt;- repo_info_gh$contributors\nparam1 &lt;- sum(nna_contr &gt; 10)/length(nna_contr)\nparam2 &lt;- sum(nna_contr &gt; 1)/length(nna_contr)\nparam3 &lt;- sum(nna_contr &lt;= 5)/length(nna_contr)\n\n\nMore than 10 contributors: 25.2%\nMore than 1 contributor: 80.1%\nBetween 1 and 5 contributors: 60%"
  },
  {
    "objectID": "index.html#number-of-repositories-per-tag",
    "href": "index.html#number-of-repositories-per-tag",
    "title": "Glittr stats",
    "section": "Number of repositories per tag",
    "text": "Number of repositories per tag\nThis is figure 2C in the manuscript.\n\ntag_freq_plot &lt;- tag_df |&gt;\n  filter(repositories &gt; 10) |&gt;\n  ggplot(aes(x = reorder(name, repositories),\n             y = repositories, fill = category)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_fill_manual(values = glittr_cols) +\n  ggtitle(\"Tags with &gt; 10 repositories\") +\n  ylab(\"Number of repositories\") +\n  annotate(geom = \"text\", x = 2, y = 150,\n           label = paste(\"Total number of tags: \",\n                         nrow(tag_df)),\n           color=\"black\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.title.y = element_blank())\n\nprint(tag_freq_plot)\n\n\n\n\n\n\nFigure 3: Number of repostories per tag, colored by category.\n\n\n\n\nAnd a table with the actual numbers.\n\ntag_df |&gt;\n  filter(repositories &gt; 10) |&gt;\n  arrange(desc(repositories)) |&gt;\n  knitr::kable(row.names = FALSE)\n\n\nTable 2: Number of repositories per tag\n\n\n\n\n\n\n\n\n\nname\ncategory\nrepositories\n\n\n\nR\nScripting and languages\n267\n\n\nPython\nScripting and languages\n104\n\n\nTranscriptomics\nOmics analysis\n88\n\n\nRNA-seq\nOmics analysis\n83\n\n\nNext generation sequencing\nOmics analysis\n64\n\n\nStatistics\nStatistics and machine learning\n61\n\n\nData science\nStatistics and machine learning\n55\n\n\nGenomics\nOmics analysis\n53\n\n\nMachine learning\nStatistics and machine learning\n51\n\n\nSingle-cell sequencing\nOmics analysis\n50\n\n\nData management\nReproducibility and data management\n42\n\n\nUnix/Linux\nScripting and languages\n40\n\n\nReproducibility\nReproducibility and data management\n39\n\n\nData visualization\nScripting and languages\n36\n\n\nFAIR data\nReproducibility and data management\n35\n\n\nGeneral\nOthers\n34\n\n\nVariant analysis\nOmics analysis\n30\n\n\nVersion control\nScripting and languages\n27\n\n\nWorkflows\nComputational methods and pipelines\n21\n\n\nShiny\nScripting and languages\n20\n\n\nContainerization\nComputational methods and pipelines\n20\n\n\nMetagenomics\nOmics analysis\n18\n\n\nDocker\nComputational methods and pipelines\n16\n\n\nChIP-seq\nOmics analysis\n16\n\n\nJulia\nScripting and languages\n13\n\n\nNextflow\nComputational methods and pipelines\n12\n\n\nATAC-seq\nOmics analysis\n12\n\n\nEpigenetics\nOmics analysis\n12\n\n\nQuarto\nScripting and languages\n11\n\n\nImage analysis\nComputational methods and pipelines\n11"
  },
  {
    "objectID": "index.html#number-of-repositories-by-author",
    "href": "index.html#number-of-repositories-by-author",
    "title": "Glittr stats",
    "section": "Number of repositories by author",
    "text": "Number of repositories by author\nThis is figure 2D in the manuscript.\n\nauthor_freq &lt;- table(author_name = repo_info$author_name, \n                     main_category = repo_info$main_category) |&gt;\n  as.data.frame()\n\nauthor_freq$main_category &lt;- factor(author_freq$main_category,\n                                     levels = names(cat_table))\n\nrepos_per_author &lt;- table(repo_info$author_name)\n\nlf_authors &lt;- names(repos_per_author)[repos_per_author &lt; 5]\n\nauthor_freq_plot &lt;- author_freq |&gt;\n  filter(!author_name %in% lf_authors) |&gt;\n  arrange(Freq) |&gt;\n  ggplot(aes(x = reorder(author_name, Freq), y = Freq, fill = main_category)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  ggtitle(\"Author or organization\") +\n  ylab(\"Number of repositories\") +\n  scale_fill_manual(values = glittr_cols) +\n  annotate(geom = \"text\", x = 2, y = 30,\n           label = paste(\"Authors with &lt; 5 repos: \",\n                         length(lf_authors)),\n           color=\"black\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.title.y = element_blank())\n\nprint(author_freq_plot)\n\n\n\n\n\n\nFigure 4: Number of repositories per author colored by category\n\n\n\n\nAnd a table with the actual numbers.\n\ntable(repo_info$author_name) |&gt;\n  as.data.frame() |&gt;\n  filter(Freq &gt;= 5) |&gt;\n  arrange(desc(Freq)) |&gt;\n  knitr::kable()\n\n\nTable 3: Number of repositories per author\n\n\n\n\nVar1\nFreq\n\n\n\ncarpentries-incubator\n46\n\n\nsib-swiss\n28\n\n\nNBISweden\n22\n\n\nposit-conf-2023\n20\n\n\nucdavis-bioinformatics-training\n18\n\n\nhbctraining\n17\n\n\nposit-conf-2024\n17\n\n\ndatacarpentry\n16\n\n\nbioinformaticsdotca\n14\n\n\nbioinformatics-core-shared-training\n13\n\n\nbioinformatics-ca\n10\n\n\nGTPB\n10\n\n\nfhdsl\n9\n\n\nrstudio-conf-2022\n9\n\n\nlearnbyexample\n8\n\n\nRockefellerUniversity\n7\n\n\nsemacu\n7\n\n\nbiocorecrg\n6\n\n\nJuliaAcademy\n6\n\n\nswcarpentry\n6\n\n\ncambiotraining\n5\n\n\ncarpentries-lab\n5\n\n\nhadley\n5\n\n\njhudsl\n5"
  },
  {
    "objectID": "index.html#number-of-repositories-per-license",
    "href": "index.html#number-of-repositories-per-license",
    "title": "Glittr stats",
    "section": "Number of repositories per license",
    "text": "Number of repositories per license\nThis is figure 2E in the manuscript.\n\nlic_freq_data &lt;- table(license = repo_info$license,\n                       main_category = repo_info$main_category) |&gt;\n  as.data.frame()\n\nlic_freq_data$main_category &lt;- factor(lic_freq_data$main_category,\n                                     levels = names(cat_table))\n\nlic_freq_plot &lt;- lic_freq_data |&gt;\n  ggplot(aes(x = reorder(license, Freq), y = Freq, fill = main_category)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_fill_manual(values = glittr_cols) +\n  theme_classic() +\n  ggtitle(\"License type\") +\n  ylab(\"Number of repositories\") +\n  theme(legend.position = \"none\",\n        axis.title.y = element_blank())\n\nprint(lic_freq_plot)\n\n\n\n\n\n\nFigure 5: Number of repositories per license\n\n\n\n\nAnd a table with the actual numbers.\n\nrepo_info$license |&gt;\n  table() |&gt;\n  as.data.frame() |&gt;\n  mutate(perc = round(Freq/nrow(repo_info)*100, 1)) |&gt;\n  arrange(desc(Freq)) |&gt;\n  knitr::kable()\n\n\nTable 4: Number of repositories per license\n\n\n\n\nVar1\nFreq\nperc\n\n\n\nother\n226\n33.7\n\n\nnone\n192\n28.7\n\n\nmit\n74\n11.0\n\n\ncc-by-sa-4.0\n48\n7.2\n\n\ncc-by-4.0\n44\n6.6\n\n\ngpl-3.0\n30\n4.5\n\n\ncc0-1.0\n26\n3.9\n\n\napache-2.0\n12\n1.8\n\n\nbsd-3-clause\n12\n1.8\n\n\nagpl-3.0\n2\n0.3\n\n\nartistic-2.0\n2\n0.3\n\n\nunlicense\n1\n0.1\n\n\nwtfpl\n1\n0.1"
  },
  {
    "objectID": "index.html#number-of-repositories-per-country",
    "href": "index.html#number-of-repositories-per-country",
    "title": "Glittr stats",
    "section": "Number of repositories per country",
    "text": "Number of repositories per country\nThis is figure 2F in the mansucript.\n\ncountry_freq &lt;- table(country = repo_info$country, \n                      main_category = repo_info$main_category) |&gt;\n  as.data.frame()\n\ncountry_freq$main_category &lt;- factor(country_freq$main_category,\n                                     levels = names(cat_table))\n\ncountry_freq_plot &lt;- country_freq |&gt;\n  filter(country != \"undefined\") |&gt;\n  ggplot(aes(x = reorder(country, Freq), y = Freq, fill = main_category)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  ggtitle(\"Country\") +\n  ylab(\"Number of repositories\") +\n  scale_fill_manual(values = glittr_cols) +\n  annotate(geom = \"text\", x = 2, y = 70,\n           label = paste(\"Repos with undefined country: \",\n                         sum(repo_info$country == \"undefined\")),\n           color=\"black\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.title.y = element_blank())\n\nprint(country_freq_plot)\n\n\n\n\n\n\nFigure 6: Number of repositories per country colored by category\n\n\n\n\nAnd a table with the actual numbers.\n\nrepo_info$country |&gt; \n  table() |&gt; \n  as.data.frame() |&gt; \n  arrange(desc(Freq)) |&gt; \n  knitr::kable()\n\n\nTable 5: Number of repositories per country\n\n\n\n\nVar1\nFreq\n\n\n\nundefined\n269\n\n\nUnited States\n181\n\n\nCanada\n32\n\n\nSwitzerland\n31\n\n\nSweden\n23\n\n\nUnited Kingdom\n23\n\n\nAustralia\n15\n\n\nFrance\n14\n\n\nGermany\n14\n\n\nNetherlands\n12\n\n\nPortugal\n11\n\n\nBelgium\n10\n\n\nSpain\n8\n\n\nDenmark\n4\n\n\nIndia\n4\n\n\nNorway\n4\n\n\nIreland\n3\n\n\nItaly\n3\n\n\nBulgaria\n2\n\n\nArgentina\n1\n\n\nChina\n1\n\n\nFinland\n1\n\n\nLuxembourg\n1\n\n\nMexico\n1\n\n\nPoland\n1\n\n\nUkraine\n1"
  },
  {
    "objectID": "index.html#number-of-outlinks-by-repo",
    "href": "index.html#number-of-outlinks-by-repo",
    "title": "Glittr stats",
    "section": "Number of outlinks by repo",
    "text": "Number of outlinks by repo\nHere, we use the site data from matomo in order to investigate what visitors of Glittr.org have clicked on. This gives us an idea about which repositories and topics are popular among users. In Figure 7 we see that TheAlgorithms/Python was the most popular repository with 328 clicks.\n\nvisits_by_entry |&gt;\n  slice(1:30) |&gt;\n  ggplot(aes(x = reorder(associated_entry, total_visits),\n             y = total_visits, fill = main_category)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_fill_manual(values = glittr_cols) +\n  ggtitle(\"Top 30 of most outlinked repos\") +\n  ylab(\"Number of outlinks\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.title.y = element_blank())\n\n\n\n\n\n\nFigure 7: Top 30 of most visited repos from Glittr.org in the past year\n\n\n\n\n\nvisits_by_entry |&gt;\n  select(associated_entry, total_visits) |&gt;\n  rename(repository = associated_entry) |&gt;\n  slice(1:30) |&gt;\n  knitr::kable()\n\n\nTable 6: Number visits per repository\n\n\n\n\nrepository\ntotal_visits\n\n\n\nTheAlgorithms/Python\n328\n\n\njakevdp/PythonDataScienceHandbook\n136\n\n\nrealpython/python-guide\n106\n\n\nISUgenomics/bioinformatics-workbook\n96\n\n\ngalaxyproject/training-material\n95\n\n\ncxli233/FriendsDontLetFriends\n87\n\n\nmlabonne/llm-course\n86\n\n\nlexfridman/mit-deep-learning\n81\n\n\ntheislab/single-cell-tutorial\n71\n\n\nzhiwehu/Python-programming-exercises\n67\n\n\nbobbyiliev/introduction-to-bash-scripting\n61\n\n\nhbctraining/Training-modules\n57\n\n\nhadley/r4ds\n54\n\n\ntrekhleb/learn-python\n49\n\n\njeroenjanssens/data-science-at-the-command-line\n47\n\n\ninstillai/TensorFlow-Course\n45\n\n\nYorko/mlcourse.ai\n43\n\n\nDataTalksClub/data-engineering-zoomcamp\n42\n\n\ngenome/bfx-workshop\n37\n\n\nrstudio/bookdown\n37\n\n\nsib-swiss/single-cell-training\n37\n\n\ngoogle/comprehensive-rust\n35\n\n\nharvardinformatics/learning-bioinformatics-at-home\n35\n\n\nrust-lang/rustlings\n35\n\n\nhbctraining/scRNA-seq_online\n34\n\n\nclauswilke/dataviz\n33\n\n\nrmcelreath/stat_rethinking_2022\n32\n\n\nhadley/ggplot2-book\n29\n\n\nFunctional-Genomics-Lab/Applied-Genomics\n25\n\n\nsib-swiss/NGS-variants-training\n25\n\n\n\n\n\n\n\n\nIt becomes more interesting when we aggregate the data per main tag (Figure 8). This gives us an idea of topic which people are looking for when visiting glittr.org. The most popular topic is Python with 772 outlinks.\n\nvisits_by_main_tag |&gt;\n  slice(1:30) |&gt;\n  ggplot(aes(x = reorder(main_tag, total_visits),\n             y = total_visits, fill = category)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_fill_manual(values = glittr_cols) +\n  ggtitle(\"Top 30 of most outlinked main tags\") +\n  ylab(\"Number of outlinks\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.title.y = element_blank())\n\n\n\n\n\n\nFigure 8: Top 30 of most popular main tags from Glittr.org in the past year\n\n\n\n\nWhen we normalize the visits by number of repositories per tag (Figure 9), we can get an idea where training materials might be lacking. A high number here show repositories that are quite unique in what they teach, but are still popular. Here, we see that there are 2 repositires with the main tag Rust with an average of 35 outlinks.\n\nvisits_by_main_tag |&gt;\n  arrange(desc(visits_per_repo)) |&gt;\n  slice(1:30) |&gt;\n  ggplot(aes(x = reorder(main_tag, visits_per_repo),\n             y = visits_per_repo, fill = category)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() +\n  scale_fill_manual(values = glittr_cols) +\n  ggtitle(\"Top 30 of most outlinked main tags normalized by repo number\") +\n  ylab(\"Number of outlinks per tag/number of repositories having tag\") +\n  theme_classic() +\n  theme(legend.position = \"none\",\n        axis.title.y = element_blank())\n\n\n\n\n\n\nFigure 9: Top 30 of most popular main tags normalized per repo from Glittr.org in the past year\n\n\n\n\n\nvisits_by_main_tag |&gt;\n  slice(1:30) |&gt;\n  knitr::kable()\n\n\nTable 7: Number visits per tag\n\n\n\n\n\n\n\n\n\n\n\nmain_tag\ntotal_visits\ncategory\nrepositories\nvisits_per_repo\n\n\n\nRust\n70\nScripting and languages\n2\n35.0000000\n\n\nGalaxy\n95\nComputational methods and pipelines\n3\n31.6666667\n\n\nArtificial intelligence\n106\nStatistics and machine learning\n6\n17.6666667\n\n\nGeneral\n290\nOthers\n34\n8.5294118\n\n\nPython\n772\nScripting and languages\n104\n7.4230769\n\n\nSpatial transcriptomics\n66\nOmics analysis\n10\n6.6000000\n\n\nMultiomics\n23\nOmics analysis\n4\n5.7500000\n\n\nData visualization\n181\nScripting and languages\n36\n5.0277778\n\n\nMachine learning\n253\nStatistics and machine learning\n51\n4.9607843\n\n\nSingle-cell sequencing\n216\nOmics analysis\n50\n4.3200000\n\n\nWorkflows\n86\nComputational methods and pipelines\n21\n4.0952381\n\n\nUnix/Linux\n132\nScripting and languages\n40\n3.3000000\n\n\nProteomics\n18\nOmics analysis\n8\n2.2500000\n\n\nLong read sequencing\n20\nOmics analysis\n9\n2.2222222\n\n\nGenomics\n117\nOmics analysis\n53\n2.2075472\n\n\nQuarto\n23\nScripting and languages\n11\n2.0909091\n\n\nC/C++\n2\nScripting and languages\n1\n2.0000000\n\n\nMATLAB/Octave\n2\nScripting and languages\n1\n2.0000000\n\n\nGNU Make\n5\nScripting and languages\n3\n1.6666667\n\n\nPathways and Networks\n8\nOmics analysis\n5\n1.6000000\n\n\nContainerization\n27\nComputational methods and pipelines\n20\n1.3500000\n\n\nStatistics\n80\nStatistics and machine learning\n61\n1.3114754\n\n\nEpigenetics\n15\nOmics analysis\n12\n1.2500000\n\n\nCloud computing\n12\nComputational methods and pipelines\n10\n1.2000000\n\n\nData science\n58\nStatistics and machine learning\n55\n1.0545455\n\n\nNext generation sequencing\n63\nOmics analysis\n64\n0.9843750\n\n\nR\n245\nScripting and languages\n267\n0.9176030\n\n\nMetagenomics\n16\nOmics analysis\n18\n0.8888889\n\n\nVariant analysis\n25\nOmics analysis\n30\n0.8333333\n\n\nTranscriptomics\n59\nOmics analysis\n88\n0.6704545\n\n\n\n\n\n\n\n\nWe can also check popularity by namespace, i.e. author (Table 8).\n\nvisits_by_namespace |&gt;\n  slice(1:30) |&gt;\n  knitr::kable()\n\n\nTable 8: Number visits per namespace\n\n\n\n\nauthor_name\ntotal_visits\n\n\n\nTheAlgorithms\n328\n\n\nsib-swiss\n206\n\n\njakevdp\n136\n\n\nhadley\n111\n\n\nhbctraining\n110\n\n\nrealpython\n106\n\n\nNBISweden\n98\n\n\nISUgenomics\n96\n\n\ngalaxyproject\n95\n\n\ncxli233\n87\n\n\nmlabonne\n86\n\n\ntheislab\n86\n\n\nlexfridman\n81\n\n\nzhiwehu\n67\n\n\ncarpentries-incubator\n63\n\n\nbobbyiliev\n61\n\n\ntrekhleb\n49\n\n\njeroenjanssens\n47\n\n\ninstillai\n45\n\n\nYorko\n43\n\n\nDataTalksClub\n42\n\n\nrstudio\n41\n\n\ngenome\n37\n\n\ngoogle\n35\n\n\nharvardinformatics\n35\n\n\nrust-lang\n35\n\n\nclauswilke\n33\n\n\nrmcelreath\n32\n\n\nAllenDowney\n31\n\n\ngriffithlab\n30"
  },
  {
    "objectID": "index.html#summary-plot",
    "href": "index.html#summary-plot",
    "title": "Glittr stats",
    "section": "Summary plot",
    "text": "Summary plot\nFull figure 2 of the manuscript.\n\np &lt;- plot_grid(cat_count_plot, contributors_plot, \n          tag_freq_plot, author_freq_plot,  \n          lic_freq_plot, country_freq_plot,\n          ncol = 2, labels = LETTERS[1:6],\n          rel_heights = c(2,3,3))\n\nggsave(\"grid_plot_fig2.pdf\", width = 10, height = 10)\nggsave(\"grid_plot_fig2.eps\", width = 10, height = 10)"
  }
]